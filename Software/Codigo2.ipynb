{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvxl55PLzICM"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# achi = np.load('antes_fatigachirre.npy')\n",
        "# aari = np.load('antes_fatigaarri.npy')\n",
        "# anat = np.load('antes_fatiganat1.npy')\n",
        "# agian = np.load('antes_fatigagian.npy')\n",
        "# acuti = np.load('antes_fatigacuti.npy')\n",
        "# armschi = np.load('antes_fatigarmschirre.npy')\n",
        "# armsari = np.load('antes_fatigarmsari.npy')\n",
        "# armsnat = np.load('antes_fatigarmsnat1.npy')\n",
        "# armsgian = np.load('antes_fatigarmsgian.npy')\n",
        "# armscuti = np.load('antes_fatigarmscuti.npy')\n",
        "# dchi = np.load('despues_fatigachirre.npy')\n",
        "# dari = np.load('despues_fatigaari.npy')\n",
        "# dnat = np.load('despues_fatiganat1.npy')\n",
        "# dgian = np.load('despues_fatigagian.npy')\n",
        "# dcuti = np.load('despues_fatigacuti.npy')\n",
        "# drmschi = np.load('despues_fatigarmschirre.npy')\n",
        "# drmsari = np.load('despues_fatigarmsari.npy')\n",
        "# drmsnat = np.load('despues_fatigarmsnat1.npy')\n",
        "# drmsgian = np.load('despues_fatigarmsgian.npy')\n",
        "# drmscuti = np.load('despues_fatigarmscuti.npy')\n",
        "\n",
        "# emg=[achi,aari,anat,agian,acuti,armschi,armsari,armsnat,armsgian,armscuti,dchi,dari,dnat,dgian,dcuti,drmschi,drmsari,drmsnat,drmsgian,drmscuti]\n"
      ],
      "metadata": {
        "id": "tOk7Gm0435RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_frecuencia_dominante(signal, frecuencia_muestreo):\n",
        "    fft_resultado = np.fft.fft(signal)\n",
        "    # Obtener las frecuencias correspondientes\n",
        "    frecuencias = np.fft.fftfreq(len(signal), 1/frecuencia_muestreo)\n",
        "    # Ignorar las frecuencias negativas (simetría en la FFT)\n",
        "    frecuencias_positivas = frecuencias[frecuencias > 0]\n",
        "    fft_resultado_positivo = fft_resultado[frecuencias > 0]\n",
        "\n",
        "    # Encontrar la frecuencia con la amplitud máxima\n",
        "    frecuencia_dominante_index = np.argmax(np.abs(fft_resultado_positivo))\n",
        "    frecuencia_dominante = frecuencias_positivas[frecuencia_dominante_index]\n",
        "\n",
        "    return frecuencia_dominante"
      ],
      "metadata": {
        "id": "aJeEhk3PNnJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "import scipy.stats\n",
        "\n",
        "def divide_en_ventanas(signal, ventana_size, step_size, Fs):\n",
        "    ventanas = []\n",
        "    for i in range(0, len(signal) - ventana_size + 1, step_size):\n",
        "        ventana = signal[i:i + ventana_size]\n",
        "        ventanas.append(ventana)\n",
        "    return ventanas\n",
        "\n",
        "# def graficar_ventanas(arrays, Fs, clase):\n",
        "#     for i, ventana in enumerate(arrays):\n",
        "#         tiempo = np.arange(1, len(ventana) + 1) / Fs\n",
        "#         plt.figure()\n",
        "#         plt.plot(tiempo, ventana, label=f'Ventana {i + 1}')\n",
        "#         plt.xlabel('Tiempo (s)')\n",
        "#         plt.ylabel('Amplitud en mV')\n",
        "#         plt.title(f'Clase {clase}')\n",
        "#         plt.legend(loc='upper right')\n",
        "#         plt.grid(linestyle=':')\n",
        "#         plt.show()\n",
        "\n",
        "\n",
        "def wavelet(signal):\n",
        "    # Realizar la descomposición wavelet\n",
        "    coeficientes = pywt.wavedec(signal, 'db7', level=4)\n",
        "    return coeficientes\n",
        "\n",
        "datosa = np.load('l_auxa.npy')\n",
        "datosd = np.load('l_auxd.npy')\n",
        "\n",
        "Fs = 1000\n",
        "ventana_size = int(10 * Fs)\n",
        "step_size = int(10 * Fs)\n",
        "\n",
        "antes = []\n",
        "despues = []\n",
        "antesrms = []\n",
        "despuesrms = []\n",
        "\n",
        "rms=[]\n",
        "mean=[]\n",
        "std=[]\n",
        "amplitude=[]\n",
        "max_sample=[]\n",
        "min_sample=[]\n",
        "freq=[]\n",
        "\n",
        "rmsw1=[]\n",
        "meanw1=[]\n",
        "stdw1=[]\n",
        "amplitudew1=[]\n",
        "max_samplew1=[]\n",
        "min_samplew1=[]\n",
        "kurtosisw1=[]\n",
        "\n",
        "rmsw2=[]\n",
        "meanw2=[]\n",
        "stdw2=[]\n",
        "amplitudew2=[]\n",
        "max_samplew2=[]\n",
        "min_samplew2=[]\n",
        "kurtosisw2=[]\n",
        "\n",
        "for i in datosa:\n",
        "  ventanas_antes_fatiga = divide_en_ventanas(i, ventana_size, step_size, Fs)\n",
        "  antes.extend(ventanas_antes_fatiga)\n",
        "for i in datosd:\n",
        "  ventanas_antes_fatiga = divide_en_ventanas(i, ventana_size, step_size, Fs)\n",
        "  despues.extend(ventanas_antes_fatiga)\n",
        "#print(despues)\n",
        "\n",
        "for i in antes+despues:\n",
        "  rms1 = np.sqrt(np.mean(i ** 2))\n",
        "  mean1 = np.mean(i)\n",
        "  std1 = np.std(i)\n",
        "  amplitude1 = np.max(i) - np.min(i)\n",
        "  max_sample1 = np.max(i)\n",
        "  min_sample1 = np.min(i)\n",
        "  fre=calcular_frecuencia_dominante(i, 1000)\n",
        "  coef=wavelet(i)\n",
        "\n",
        "  rms1w1 = np.sqrt(np.mean(coef[0] ** 2))\n",
        "  mean1w1 = np.mean(coef[0])\n",
        "  std1w1 = np.std(coef[0])\n",
        "  amplitude1w1 = np.max(coef[0]) - np.min(coef[0])\n",
        "  max_sample1w1 = np.max(coef[0])\n",
        "  min_sample1w1 = np.min(coef[0])\n",
        "\n",
        "\n",
        "  rms1w2 = np.sqrt(np.mean(coef[1] ** 2))\n",
        "  mean1w2 = np.mean(coef[1])\n",
        "  std1w2 = np.std(coef[1])\n",
        "  amplitude1w2 = np.max(coef[1]) - np.min(coef[1])\n",
        "  max_sample1w2 = np.max(coef[1])\n",
        "  min_sample1w2 = np.min(coef[1])\n",
        "\n",
        "  rms.append(rms1)\n",
        "  mean.append(mean1)\n",
        "  std.append(std1)\n",
        "  amplitude.append(amplitude1)\n",
        "  max_sample.append(max_sample1)\n",
        "  min_sample.append(min_sample1)\n",
        "  freq.append(fre)\n",
        "\n",
        "  rmsw1.append(rms1w1)\n",
        "  meanw1.append(mean1w1)\n",
        "  stdw1.append(std1w1)\n",
        "  amplitudew1.append(amplitude1w1)\n",
        "  max_samplew1.append(max_sample1w1)\n",
        "  min_samplew1.append(min_sample1w1)\n",
        "\n",
        "  rmsw2.append(rms1w2)\n",
        "  meanw2.append(mean1w2)\n",
        "  stdw2.append(std1w2)\n",
        "  amplitudew2.append(amplitude1w2)\n",
        "  max_samplew2.append(max_sample1w2)\n",
        "  min_samplew2.append(min_sample1w2)\n",
        "\n",
        "print(kurtosisw1)\n",
        "clase = [0] * 300 + [1] * (300)\n",
        "# print(len(clase))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sE8uZ_0cw9I",
        "outputId": "fba2e91c-ad36-466a-a066-76b1c21bfa90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Wavelet coeff\n",
        "# kernel otro tipo\n",
        "# segmentar 10 sec\n",
        "#\n",
        "\n",
        "\n",
        "# Datos de ejemplo (reemplázalos con tus datos reales)\n",
        "data = {\n",
        "    'RMS_Stat': rms,  # Datos de RMS\n",
        "    'Media_Stat': mean,  # Datos de Media\n",
        "    'Desviacion_Estandar_Stat': std,  # Datos de Desviación Estándar\n",
        "    'Amplitud_Stat': amplitude,  # Datos de Amplitud\n",
        "    'Maximo_Stat': max_sample,  # Datos de Máximo\n",
        "\n",
        "    'RMSw1_Stat': rmsw1,  # Datos de RMS\n",
        "    'Mediaw1_Stat': meanw1,  # Datos de Media\n",
        "    'Desviacion_Estandarw1_Stat': stdw1,  # Datos de Desviación Estándar\n",
        "\n",
        "    'RMSw2_Stat': rmsw2,  # Datos de RMS\n",
        "    'Mediaw2_Stat': meanw2,  # Datos de Media\n",
        "    'Desviacion_Estandarw2_Stat': stdw2,  # Datos de Desviación Estándar\n",
        "\n",
        "    'Clasificacion': clase,  # Etiquetas de clasificación (0 o 1)\n",
        "}\n",
        "\n",
        "# Crear DataFrame a partir de los datos\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Dividir el conjunto de datos en características (X) y etiquetas (y)\n",
        "X = df.drop('Clasificacion', axis=1).to_numpy()\n",
        "y = df['Clasificacion'].to_numpy()\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar las características usando StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Crear y entrenar el clasificador SVM\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:\\n', classification_rep)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5dpon6XtFxX",
        "outputId": "b35c949e-0662-4249-ac06-54a72d927e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90        62\n",
            "           1       0.90      0.90      0.90        58\n",
            "\n",
            "    accuracy                           0.90       120\n",
            "   macro avg       0.90      0.90      0.90       120\n",
            "weighted avg       0.90      0.90      0.90       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "cZyegX1Jj2ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlEkT7fm35gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mb3UBvt35kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BU0cCmTj35nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcTslvmy35qz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}